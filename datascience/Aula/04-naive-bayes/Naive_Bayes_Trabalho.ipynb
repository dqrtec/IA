{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [x for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo carData.csv foi carregado com 1728 linhas\n"
     ]
    }
   ],
   "source": [
    "filename = 'carData.csv'\n",
    "dataset = loadCsv(filename)\n",
    "print(('O arquivo {0} foi carregado com {1} linhas').format(filename, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    testSet = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(testSet))\n",
    "        trainSet.append(testSet.pop(index))\n",
    "    return [trainSet, testSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitRatio = 0.7\n",
    "newDF = df.values.tolist()\n",
    "train, teste = splitDataset(newDF, splitRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def separateFeaturesByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset.iloc[i]\n",
    "        if (row[-1] not in separated):\n",
    "            separated[row[-1]] = []\n",
    "        separated[row[-1]].append(row)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableFrequency(dataset):\n",
    "    dic = {}\n",
    "    attributes = dataset.columns\n",
    "    for attribute in attributes:\n",
    "        for value in dataset[attribute].unique():\n",
    "            if value not in dic.keys():\n",
    "                dic[value] = []\n",
    "            dic[value].append((dataset.groupby(attribute)[attribute].count()[value], attribute))\n",
    "    for value in dataset[dataset.columns[-1]].unique(): # Delete class (the last attribute)\n",
    "        del dic[value]\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencyByClass(dataset):\n",
    "    separated = separateFeaturesByClass(dataset)\n",
    "    frequency = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        frequency[classValue] = tableFrequency(pd.DataFrame(instances))\n",
    "        \n",
    "    for classValue in dataset.classe.unique():\n",
    "        #index = 0\n",
    "        for attr in dataset.columns[:-1]:\n",
    "            for value in dataset[attr]:\n",
    "                if value not in frequency[classValue]:\n",
    "                    frequency[classValue][value] = [(0, attr)]\n",
    "            #index += 1\n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbByAttribute(dataset, attr):\n",
    "    frequencyClass = frequencyByClass(dataset)\n",
    "    frequencyClassValue = {key: [] for key in frequencyClass.keys()}\n",
    "    totalValuesByClass = {key: 0 for key in frequencyClass.keys()}\n",
    "    freqByValue = {key: 0 for key in dataset[:][attr]}\n",
    "\n",
    "    frequenciesClassKeys, frequenciesClassValues = zip(*frequencyByClass(dataset).items())\n",
    "    for classIndex in range(len(frequenciesClassKeys)):\n",
    "    \n",
    "        keys = frequenciesClassValues[classIndex].keys()\n",
    "\n",
    "        for key in keys:\n",
    "            for freq in frequenciesClassValues[classIndex][key]:                      \n",
    "                if freq[1] == attr:\n",
    "                    frequencyClassValue[frequenciesClassKeys[classIndex]].append((key, freq[0]))\n",
    "                    freqByValue[key] += freq[0]\n",
    "                    totalValuesByClass[frequenciesClassKeys[classIndex]] += freq[0]\n",
    "            \n",
    "    totalValues = sum(totalValuesByClass.values())\n",
    "    probByClass = {key: totalValuesByClass[key]/totalValues for key in totalValuesByClass}\n",
    "    probByValue = {key: value/totalValues for key, value in freqByValue.items()}\n",
    "    probByClassValue = {key: [] for key in totalValuesByClass}\n",
    "        \n",
    "    for key in frequenciesClassKeys:\n",
    "        for valueTuple, freqTuple in frequencyClassValue[key]:\n",
    "            probByClassValue[key].append((valueTuple, freqTuple/totalValuesByClass[key]))\n",
    "        \n",
    "    return [probByClass, probByValue, probByClassValue]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableProbability(dataset):\n",
    "    tableProb = {}\n",
    "    for attr in dataset.columns[:-1]:\n",
    "        tableProb[attr] = calculateProbByAttribute(dataset, attr)\n",
    "        \n",
    "    return tableProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "\n",
    "    higherProbability = -1\n",
    "    classHigherProbability = None\n",
    "    \n",
    "    attributes = list(summaries.keys())\n",
    "    randomAttribute = attributes[0]\n",
    "    classes = list(summaries[randomAttribute][0].keys())\n",
    "    \n",
    "    for classValue in classes:\n",
    "        prob = 1\n",
    "        for index in range(len(attributes)):\n",
    "            probClass = summaries[attributes[index]][0][classValue]\n",
    "            probValue = summaries[attributes[index]][1][inputVector[index]]\n",
    "            valueInClass = summaries[attributes[index]][2][classValue]\n",
    "\n",
    "            for probValueClass in valueInClass:\n",
    "                if probValueClass[0] == inputVector[index]:\n",
    "                    probIntersValueClass = probValueClass[1]\n",
    "                    \n",
    "            prob = prob * (probIntersValueClass / probValue)\n",
    "        prob = prob * probClass\n",
    "        \n",
    "        if prob > higherProbability:\n",
    "            higherProbability = prob\n",
    "            classHigherProbability = classValue\n",
    "            \n",
    "    return classHigherProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet.iloc[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet.iloc[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filename = 'carData.csv'\n",
    "\n",
    "    datasetColumns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'classe']\n",
    "    df = pd.read_csv(filename, sep=',', names=datasetColumns)\n",
    "    dataset = df.values.tolist()\n",
    "    \n",
    "    splitRatio = 0.75\n",
    "    trainSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    \n",
    "    print(('Dataset {0}, Training {1}, Test {2}').format(len(dataset), len(trainSet), len(testSet)))\n",
    "\n",
    "    trainingSet = pd.DataFrame(trainSet, columns=datasetColumns)\n",
    "    testingSet = pd.DataFrame(testSet, columns=datasetColumns)\n",
    "    \n",
    "    summary = tableProbability(trainingSet)\n",
    "    predictions = getPredictions(summary, testingSet)\n",
    "    accuracy = getAccuracy(testingSet, predictions)\n",
    "    \n",
    "    print(('Acurácia de {:.3f}%').format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1728, Training 1296, Test 432\n",
      "Acurácia de 74.769%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "df = pd.read_csv(\"carData.csv\",names=[\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"Classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data into numerical\n",
    "df = df.replace('vhigh', 4)\n",
    "df = df.replace('high', 3)\n",
    "df = df.replace('med', 2)\n",
    "df = df.replace('low', 1)\n",
    "df = df.replace('more', 6)\n",
    "df = df.replace('big', 3)\n",
    "df = df.replace('small', 1)\n",
    "df = df.replace('unacc', 1)\n",
    "df = df.replace('acc', 2)\n",
    "df = df.replace('good', 3)\n",
    "df = df.replace('vgood', 4)\n",
    "df = df.replace('5more', 6)\n",
    "df = df.replace('2', 2)\n",
    "df = df.replace('3', 3)\n",
    "df = df.replace('4', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df.drop([\"Classes\"],axis=1)\n",
    "y = df[\"Classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7167630057803468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "final = accuracy_score(y_pred, y_test)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Como a acurácio dos dois foram parecidas, é possível concluir que o algoritmo implementado não se difere muito do proposto pelo scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
