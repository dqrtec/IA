{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## QuestÃ£o 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponÃ­vel no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## QuestÃ£o 2\n",
    "Crie uma versÃ£o de sua implementaÃ§Ã£o usando as funÃ§Ãµes disponÃ­veis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## QuestÃ£o 3\n",
    "\n",
    "Analise a acurÃ¡cia dos dois algoritmos e discuta a sua soluÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numColumns(dataset):\n",
    "    return len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    testSet = list(dataset)\n",
    "    \n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(testSet))\n",
    "        trainSet.append(testSet.pop(index))\n",
    "        \n",
    "    return [trainSet, testSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateFeaturesByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset.iloc[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableFrequency(dataset):\n",
    "    dic = {}\n",
    "    attributes = dataset.columns\n",
    "    for attribute in attributes:\n",
    "        for value in dataset[attribute].unique():\n",
    "            if value not in dic.keys():\n",
    "                dic[value] = []\n",
    "            dic[value].append((dataset.groupby(attribute)[attribute].count()[value], attribute))\n",
    "    for value in dataset[dataset.columns[-1]].unique(): # Delete class (the last attribute)\n",
    "        del dic[value]\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencyByClass(dataset):\n",
    "    separated = separateFeaturesByClass(dataset)\n",
    "    frequency = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        frequency[classValue] = tableFrequency(pd.DataFrame(instances))\n",
    "        \n",
    "    for classValue in dataset.classe.unique():\n",
    "        for attr in dataset.columns[:-1]:\n",
    "            for value in dataset[attr]:\n",
    "                if value not in frequency[classValue]:\n",
    "                    frequency[classValue][value] = [(0, attr)]    \n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbByAttribute(dataset, attr):\n",
    "    frequencyClass = frequencyByClass(dataset)\n",
    "    frequencyClassValue = {key: [] for key in frequencyClass.keys()}\n",
    "    totalValuesByClass = {key: 0 for key in frequencyClass.keys()}\n",
    "    freqByValue = {key: 0 for key in dataset[:][attr]}\n",
    "\n",
    "    frequenciesClassKeys, frequenciesClassValues = zip(*frequencyByClass(dataset).items())\n",
    "    for classIndex in range(len(frequenciesClassKeys)):\n",
    "    \n",
    "        keys = frequenciesClassValues[classIndex].keys()\n",
    "\n",
    "        for key in keys:\n",
    "            for freq in frequenciesClassValues[classIndex][key]:                      \n",
    "                if freq[1] == attr:\n",
    "                    frequencyClassValue[frequenciesClassKeys[classIndex]].append((key, freq[0]))\n",
    "                    freqByValue[key] += freq[0]\n",
    "                    totalValuesByClass[frequenciesClassKeys[classIndex]] += freq[0]\n",
    "            \n",
    "    totalValues = sum(totalValuesByClass.values())\n",
    "    probByClass = {key: totalValuesByClass[key]/totalValues for key in totalValuesByClass}\n",
    "    probByValue = {key: value/totalValues for key, value in freqByValue.items()}\n",
    "    probByClassValue = {key: [] for key in totalValuesByClass}\n",
    "        \n",
    "    for key in frequenciesClassKeys:\n",
    "        for valueTuple, freqTuple in frequencyClassValue[key]:\n",
    "            probByClassValue[key].append((valueTuple, freqTuple/totalValuesByClass[key]))\n",
    "        \n",
    "    return [probByClass, probByValue, probByClassValue]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableProbability(dataset):\n",
    "    tableProb = {}\n",
    "    for attr in dataset.columns[:-1]:\n",
    "        tableProb[attr] = calculateProbByAttribute(dataset, attr)\n",
    "        \n",
    "    return tableProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "\n",
    "    higherProbability = -1\n",
    "    classHigherProbability = None\n",
    "    \n",
    "    attributes = list(summaries.keys())\n",
    "    randomAttribute = attributes[0]\n",
    "    classes = list(summaries[randomAttribute][0].keys())\n",
    "    \n",
    "    for classValue in classes:\n",
    "        prob = 1\n",
    "        for index in range(len(attributes)):\n",
    "            probClass = summaries[attributes[index]][0][classValue]\n",
    "            probValue = summaries[attributes[index]][1][inputVector[index]]\n",
    "            valueInClass = summaries[attributes[index]][2][classValue]\n",
    "\n",
    "            for probValueClass in valueInClass:\n",
    "                if probValueClass[0] == inputVector[index]:\n",
    "                    probIntersValueClass = probValueClass[1]\n",
    "                    \n",
    "            prob = prob * (probIntersValueClass / probValue)\n",
    "        prob = prob * probClass\n",
    "        \n",
    "        if prob > higherProbability:\n",
    "            higherProbability = prob\n",
    "            classHigherProbability = classValue\n",
    "            \n",
    "    return classHigherProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet.iloc[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet.iloc[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filename = 'carData.csv'\n",
    "\n",
    "    datasetColumns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'classe']\n",
    "    df = pd.read_csv(filename, sep=',', names=datasetColumns)\n",
    "    dataset = df.values.tolist()\n",
    "    \n",
    "    splitRatio = 0.75\n",
    "    trainSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    \n",
    "    print(('Dataset {0}, Training {1}, Test {2}').format(len(dataset), len(trainSet), len(testSet)))\n",
    "\n",
    "    trainingSet = pd.DataFrame(trainSet, columns=datasetColumns)\n",
    "    testingSet = pd.DataFrame(testSet, columns=datasetColumns)\n",
    "    \n",
    "    summary = tableProbability(trainingSet)\n",
    "    predictions = getPredictions(summary, testingSet)\n",
    "    accuracy = getAccuracy(testingSet, predictions)\n",
    "    \n",
    "    print(('AcurÃ¡cia de {:.3f}%').format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1728, Training 1296, Test 432\n",
      "AcurÃ¡cia de 74.306%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
